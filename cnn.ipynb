{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "IMAGE_SIZE = 128\n",
    "SEED = 42\n",
    "AUTOENCODER_EPOCHS = 3\n",
    "CLASSIFIER_EPOCHS = 50\n",
    "num_classes = 5 \n",
    "class_names = [\"cardboard\", \"glass\", \"metal\", \"paper\", \"plastic\"]\n",
    "WEIGHT_DECAY = 0.001\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Flatten, Dense, Rescaling, BatchNormalization, Input\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold\n",
    "from tensorflow.keras import layers, losses, regularizers, optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = Input(shape = (IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "\n",
    "dataset_dir = \"./dataset\"\n",
    "train = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    labels='inferred',\n",
    "    # label_mode='int',\n",
    "    class_names=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    "    validation_split=0.2,\n",
    "    interpolation='bilinear',\n",
    "    subset=\"training\"\n",
    ")\n",
    "validate = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    labels='inferred',\n",
    "    # label_mode='int',\n",
    "    color_mode='rgb',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    "    validation_split=0.2,\n",
    "    interpolation='bilinear',\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "train_data = list(train)\n",
    "train_images = np.concatenate([train_data[n][0] for n in range(0, len(train_data))])\n",
    "train_labels = np.concatenate([train_data[n][1] for n in range(0, len(train_data))])\n",
    "\n",
    "test_data = list(train)\n",
    "test_images = np.concatenate([test_data[n][0] for n in range(0, len(test_data))])\n",
    "test_labels = np.concatenate([test_data[n][1] for n in range(0, len(test_data))])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(4):  # Display up to 9 images\n",
    "    ax = plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(train_images[i].astype(\"uint8\"))\n",
    "    plt.title(f\"Class: {class_names[train_labels[i]]}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(4):  # Display up to 9 images\n",
    "    ax = plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(test_images[i].astype(\"uint8\"))\n",
    "    plt.title(f\"Class: {class_names[test_labels[i]]}\")\n",
    "    plt.axis(\"off\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "flip_layer = tf.keras.layers.RandomFlip(\"horizontal_and_vertical\")\n",
    "rotation_layer = tf.keras.layers.RandomRotation(0.2)\n",
    "def change_inputs(images, labels):\n",
    "    x = flip_layer(normalization_layer(images))\n",
    "    x = rotation_layer(x)\n",
    "\n",
    "    x = tf.image.resize(x, [IMAGE_SIZE, IMAGE_SIZE], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    return x, x\n",
    "\n",
    "\n",
    "normalized_ds = train.map(change_inputs)\n",
    "normalized_vds = validate.map(change_inputs)\n",
    "# normalized_train_images = normalization_layer(train_images)\n",
    "# flipped_train_images = np.array([np.fliplr(np.flipud(img)) for img in normalized_train_images])\n",
    "# rotated_train_images = np.array([tf.image.rot90(img, k=np.random.choice([0, 1, 2, 3])) for img in flipped_train_images])\n",
    "\n",
    "# resized_train_images = np.array([tf.image.resize(img, [IMAGE_SIZE, IMAGE_SIZE], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR) for img in rotated_train_images])\n",
    "\n",
    "# train_images = np.concatenate([train_images, resized_train_images])\n",
    "# train_labels = np.concatenate([train_labels, train_labels])\n",
    "\n",
    "# shuffle_indices = np.random.permutation(len(train_images))\n",
    "# train_images = train_images[shuffle_indices]\n",
    "# train_labels = train_labels[shuffle_indices]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_images(dataset, num_images=5):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for images, _ in dataset.take(1):  # Take one batch for demonstration\n",
    "        for i in range(min(num_images, len(images))):\n",
    "            ax = plt.subplot(1, num_images, i + 1)\n",
    "            plt.imshow((images[i].numpy() * 255).astype(\"uint8\"))\n",
    "            plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "plot_images(normalized_ds)\n",
    "\n",
    "# Plot augmented validation images\n",
    "plot_images(normalized_vds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(input_shape):\n",
    "    # Encoder\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(input_shape)  # 128 x 128 x 64\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)  # 64 x 64 x 64\n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)  # 64 x 64 x 128\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)  # 32 x 32 x 128\n",
    "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)  # 32 x 32 x 256\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv3)  # 32 x 32 x 512\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    return conv4\n",
    "\n",
    "def decoder(conv4):    \n",
    "    # Decoder\n",
    "    conv5 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)  # 32 x 32 x 256\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv6 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv5)  # 32 x 32 x 128\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    up1 = UpSampling2D((2, 2))(conv6)  # 64 x 64 x 128\n",
    "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1)  # 64 x 64 x 64\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    up2 = UpSampling2D((2, 2))(conv7)  # 128 x 128 x 64\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(up2)  # 128 x 128 x 1\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Autoencoder Model\n",
    "def create_autoencoder_model():\n",
    "    autoencoder = Model(input_shape, decoder(encoder(input_shape)))\n",
    "    autoencoder.compile(loss=\"mse\", optimizer=optimizers.RMSprop())\n",
    "    return autoencoder\n",
    "\n",
    "# Training Autoencoder\n",
    "autoencoder_model = create_autoencoder_model()\n",
    "history_autoencoder = autoencoder_model.fit(normalized_ds, epochs=AUTOENCODER_EPOCHS)\n",
    "# # Encode data using the trained autoencoder\n",
    "# encoded_data = autoencoder_model.predict(normalized_vds)\n",
    "# print(f\"Encoded Data Shape: {encoded_data.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "autoencoder_model.summary()\n",
    "for i, layer in enumerate(autoencoder_model.layers):\n",
    "  print(f\"Layer {i}: {layer.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_classifier_model(autoencoder_model):\n",
    "    # Use the encoder part of the autoencoder as a feature extractor\n",
    "    encoder_output = autoencoder_model.layers[6].output  \n",
    "\n",
    "    x = layers.Flatten()(encoder_output)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    output_layer = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    classifier_model = Model(autoencoder_model.input, output_layer)\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-2, decay_steps=1000, decay_rate=0.9)\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "    # optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "    classifier_model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return classifier_model\n",
    "\n",
    "# Pass your autoencoder model when creating the classifier\n",
    "classifier_model = create_classifier_model(autoencoder_model)\n",
    "history_classifier = classifier_model.fit(train_numpy, epochs=CLASSIFIER_EPOCHS, validation_data=validate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(encoded):\n",
    "    flat = Flatten()(encoded)\n",
    "    den = Dense(128, activation='relu')(flat)\n",
    "    out = Dense(num_classes, activation='softmax')(den)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = encoder(input_shape)\n",
    "\n",
    "full_model = Model(input_shape, classifier(encode))\n",
    "full_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_folds = 5\n",
    "stratified_kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store results for each fold\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "train_data = np.concatenate([x.numpy() for x, y in train], axis=0)\n",
    "train_labels = np.concatenate([y.numpy() for x, y in train], axis=0)\n",
    "\n",
    "\n",
    "for fold, (train_indices, val_indices) in enumerate(stratified_kfold.split(train_data, train_labels)):\n",
    "    # Create and compile the model for each fold\n",
    "    classifier_model = create_classifier_model(autoencoder_model)\n",
    "\n",
    "    # Get the train and validation data for the current fold\n",
    "    train_fold_data, val_fold_data = train_data[train_indices], train_data[val_indices]\n",
    "    train_fold_labels, val_fold_labels = train_labels[train_indices], train_labels[val_indices]\n",
    "\n",
    "    # Train the model for the current fold\n",
    "    history_classifier = classifier_model.fit(\n",
    "        train_fold_data, train_fold_labels,\n",
    "        epochs=CLASSIFIER_EPOCHS,\n",
    "        validation_data=(val_fold_data, val_fold_labels)\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    val_predictions = classifier_model.predict(val_fold_data)\n",
    "    val_pred_labels = np.argmax(val_predictions, axis=1)\n",
    "\n",
    "    # Calculate and store metrics\n",
    "    accuracy_scores.append(accuracy_score(val_fold_labels, val_pred_labels))\n",
    "    precision_scores.append(precision_score(val_fold_labels, val_pred_labels, average='weighted'))\n",
    "    recall_scores.append(recall_score(val_fold_labels, val_pred_labels, average='weighted'))\n",
    "\n",
    "# Display average metrics across all folds\n",
    "print(f\"Average Accuracy: {np.mean(accuracy_scores)}\")\n",
    "print(f\"Average Precision: {np.mean(precision_scores)}\")\n",
    "print(f\"Average Recall: {np.mean(recall_scores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "validate_normalized = validate.map(change_inputs)\n",
    "validate_list = list(validate_normalized.as_numpy_iterator())\n",
    "images_and_labels = list(validate.as_numpy_iterator())\n",
    "# Predict labels for validation images\n",
    "predictions = classifier_model.predict(validate)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "y = np.concatenate([y for x, y in validate], axis=0)\n",
    "\n",
    "# Display a few validation images along with their true and predicted labels\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(15):  # Adjust the number of images you want to display\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    \n",
    "    # Access the batch of images and labels\n",
    "    image_batch = images_and_labels[i][0]\n",
    "    label_batch = images_and_labels[i][1]\n",
    "    \n",
    "    # Access the ith image and label from the batch\n",
    "    image = image_batch[i]\n",
    "    label = label_batch[i]\n",
    "    \n",
    "    plt.imshow(image.astype(np.uint8) / 255)\n",
    "    plt.title(f\"True: {class_names[label]}\\nPredicted: {class_names[predicted_labels[i]]}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_validation_batch(dataset, batch_size=15):\n",
    "    for images, _ in dataset.take(1):\n",
    "        return images[:batch_size]\n",
    "\n",
    "# Get a batch of images\n",
    "sample_images = get_validation_batch(validate)\n",
    "# Generate reconstructions\n",
    "reconstructed_images = autoencoder_model.predict(sample_images)\n",
    "plt.figure(figsize=(15, 5))\n",
    "# Visualize original vs. reconstructed images\n",
    "for i in range(len(sample_images)):\n",
    "    plt.subplot(2, len(sample_images), i + 1)\n",
    "    plt.imshow((sample_images[i]/255))\n",
    "    plt.title(\"O\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(2, len(sample_images), i + 1 + len(sample_images))\n",
    "    plt.imshow((reconstructed_images[i]))\n",
    "    plt.title(\"Recon\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_mining_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
